import whisperx
import torch
import gradio as gr
from datetime import datetime
from dotenv import load_dotenv
import os

# ğŸ›¡ï¸ Cargar token desde .env
load_dotenv()
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN")

# ğŸª– Detectar dispositivo
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ğŸ¤— Cargar modelo WhisperX y de alineaciÃ³n
model = whisperx.load_model("medium", device=DEVICE, compute_type="float32", language="es")
model_a, metadata = whisperx.load_align_model(language_code="es", device=DEVICE)

# ğŸ”Š DiarizaciÃ³n de hablantes (requiere login Hugging Face)
diarize_model = whisperx.DiarizationPipeline(use_auth_token=HUGGINGFACE_TOKEN)

# ğŸŒ Palabras sospechosas (recortadas para ejemplo)
palabras_sospechosas = ["whatsapp", "telegram", "discord", "ayÃºdame", "copiar", "chuleta", "trampa"]

def evaluar_audio(audio_path):
    transcription = model.transcribe(audio_path)
    aligned = whisperx.align(transcription["segments"], model_a, metadata, audio_path, DEVICE)
    diarize_segments = diarize_model(audio_path)

    # âœ¨ Fusionar segmentos con speaker
    segments = aligned["segments"]
    for segment in segments:
        for diar in diarize_segments["segments"]:
            if diar["start"] <= segment["start"] < diar["end"]:
                segment["speaker"] = diar["speaker"]
                break

    full_text = " ".join([seg["text"] for seg in segments])

    # ğŸ” Palabras no permitidas
    palabras_detectadas = [p for p in palabras_sospechosas if p.lower() in full_text.lower()]

    # ğŸ—“ï¸ Timestamp
    timestamp = datetime.now().strftime("GrabaciÃ³n %Y-%m-%d a las %H.%M.%S")

    # ğŸ“„ Generar informe
    resultado = f"TranscripciÃ³n de la {timestamp}\n\n"
    resultado += full_text + "\n\n"
    if palabras_detectadas:
        resultado += f"Palabras no permitidas detectadas: {', '.join(palabras_detectadas)}"
    else:
        resultado += "No se detectaron palabras no permitidas."

    return resultado

# ğŸš€ Crear interfaz con Gradio
interfaz = gr.Interface(
    fn=evaluar_audio,
    inputs=gr.Audio(type="filepath", label="Sube tu archivo de audio (.mp3, .wav, etc.)"),
    outputs=gr.Textbox(label="Resultado de la transcripciÃ³n y anÃ¡lisis"),
    title="ğŸ”Š Transcriptor con AnÃ¡lisis de Conductas Sospechosas",
    description="Sube un audio para transcribirlo, analizarlo y detectar palabras potencialmente sospechosas."
)

# ğŸŒ Lanzar app
if __name__ == "__main__":
    interfaz.launch()
